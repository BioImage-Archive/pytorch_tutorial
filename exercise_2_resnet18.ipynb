{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1425cfd70>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# Learning point:\n",
    "# Working with RGB images and pretrained models\n",
    "# Using a pretrained model for transfer learning\n",
    "# Task:\n",
    "# Train a ResNet18 model on the CIFAR10 dataset\n",
    "# Learn how to add data augmentation to the transformation pipeline\n",
    "\n",
    "# Note: MLP will struggle with CIFAR10 dataset due to its complexity\n",
    "# Note: CIFAR10 dataset has 3 channels (RGB) and 10 classes\n",
    "# Note: ResNet18 is a popular model for image classification tasks\n",
    "# Note: CIFAR10 dataset has 60,000 32x32 color images in 10 classes, with 6,000 images per class\n",
    "# Note: The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. \"Automobile\" includes sedans, SUVs, things of that sort. \"Truck\" includes only big trucks. Neither includes pickup trucks.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "# Model pretrained on imagenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ctr26/Documents/2024_ebi_course/pytorch_tutorial/env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ctr26/Documents/2024_ebi_course/pytorch_tutorial/env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "resnet18 = models.resnet18(pretrained=True).to(device)\n",
    "fc = nn.Linear(1000, 10)\n",
    "model = nn.Sequential(resnet18, fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Larger transformation pipeline for imagenet\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "train_data = datasets.CIFAR10(\n",
    "    root=\"./data/CIFAR10\", train=True, transform=transform, download=True\n",
    ")\n",
    "test_data = datasets.CIFAR10(\n",
    "    root=\"./data/CIFAR10\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 2.420524, Progress: [0/50000]\n",
      "Epoch: 1, Loss: 1.188298, Progress: [6400/50000]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    size = len(train_dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # loss = loss_fn(y, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"Epoch: {epoch+1}, Loss: {loss:.6f}, Progress: [{current}/{size}]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Test the model cross validation\n",
    "\n",
    "\n",
    "model.eval()\n",
    "y_pred = []\n",
    "y_true = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Disable gradient computation for evaluation to save memory and computations\n",
    "with torch.no_grad():\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for X, y in test_dataloader:\n",
    "        X = X.device()  # No device assignment since it defaults to CPU in your script\n",
    "        preds = model(X).to(device).cpu()\n",
    "        all_preds.extend(preds.argmax(1).numpy())  # Get the predicted classes\n",
    "        all_labels.extend(y.numpy())\n",
    "\n",
    "# Convert list to NumPy arrays for Scikit-Learn\n",
    "all_preds = np.array(all_preds)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(\n",
    "    all_labels, all_preds, target_names=[str(i) for i in range(10)]\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
